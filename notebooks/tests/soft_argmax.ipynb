{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/daniel/Documents/Uni/MT/poi-prediction/')\n",
    "from src.models.SubmDenseNet import SubmDenseNet\n",
    "from utils.heatmap_utils import heatmaps_to_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft-Argmax Coordinates: tensor([[[5., 5., 5.],\n",
      "         [2., 3., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SoftArgmax3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoftArgmax3D, self).__init__()\n",
    "\n",
    "    def forward(self, heatmap):\n",
    "        \"\"\"\n",
    "        Apply the soft-argmax operation on a 3D heatmap.\n",
    "        \n",
    "        Args:\n",
    "            heatmap (torch.Tensor): Input tensor of shape (b, n, h, w, d)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Soft-argmax coordinates of shape (b, n, 3)\n",
    "        \"\"\"\n",
    "        # Apply softmax to convert heatmaps into probability distributions\n",
    "        batch_size, num_maps, height, width, depth = heatmap.shape\n",
    "        probs = torch.softmax(heatmap.view(batch_size, num_maps, -1), dim=-1)\n",
    "        probs = probs.view(batch_size, num_maps, height, width, depth)\n",
    "\n",
    "        # Create coordinate grids for each dimension\n",
    "        lin_h = torch.linspace(0, height - 1, steps=height, device=heatmap.device)\n",
    "        lin_w = torch.linspace(0, width - 1, steps=width, device=heatmap.device)\n",
    "        lin_d = torch.linspace(0, depth - 1, steps=depth, device=heatmap.device)\n",
    "\n",
    "        # Expand grids to match batch size and number of maps\n",
    "        grid_h = lin_h.view(1, 1, height, 1, 1).expand(batch_size, num_maps, -1, width, depth)\n",
    "        grid_w = lin_w.view(1, 1, 1, width, 1).expand(batch_size, num_maps, height, -1, depth)\n",
    "        grid_d = lin_d.view(1, 1, 1, 1, depth).expand(batch_size, num_maps, height, width, -1)\n",
    "\n",
    "        # Compute the soft-argmax coordinates\n",
    "        soft_argmax_h = torch.sum(probs * grid_h, dim=[2, 3, 4])\n",
    "        soft_argmax_w = torch.sum(probs * grid_w, dim=[2, 3, 4])\n",
    "        soft_argmax_d = torch.sum(probs * grid_d, dim=[2, 3, 4])\n",
    "\n",
    "        # Stack results to get coordinates\n",
    "        coords = torch.stack([soft_argmax_h, soft_argmax_w, soft_argmax_d], dim=-1)\n",
    "        \n",
    "        return coords\n",
    "\n",
    "# Example of usage\n",
    "# Initialize module\n",
    "soft_argmax = SoftArgmax3D()\n",
    "\n",
    "# Create a dummy heatmap (b=1, n=2, h=10, w=10, d=10)\n",
    "heatmap = -torch.ones(1, 2, 10, 10, 10) * 100\n",
    "heatmap[0, 0, 5, 5, 5] = 1\n",
    "heatmap[0, 1, 2, 3, 4] = 1\n",
    "\n",
    "# Compute soft-argmax\n",
    "coords = soft_argmax(heatmap)\n",
    "print(\"Soft-Argmax Coordinates:\", coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "import numpy as np\n",
    "from spconv.pytorch import SparseSequential, SparseModule\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn = SubmDenseNet(\n",
    "    in_channels=1,\n",
    "    n_landmarks=10,\n",
    "    feature_l = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sparse_data(shape,\n",
    "                         num_points,\n",
    "                         num_channels,\n",
    "                         integer=False,\n",
    "                         data_range=(-1, 1),\n",
    "                         with_dense=True,\n",
    "                         dtype=np.float32,\n",
    "                         shape_scale = 1):\n",
    "    dense_shape = shape\n",
    "    ndim = len(dense_shape)\n",
    "    # num_points = np.random.randint(10, 100, size=[batch_size, ndim])\n",
    "    num_points = np.array(num_points)\n",
    "    # num_points = np.array([3, 2])\n",
    "    batch_size = len(num_points)\n",
    "    batch_indices = []\n",
    "    coors_total = np.stack(np.meshgrid(*[np.arange(0, s // shape_scale) for s in shape]),\n",
    "                           axis=-1)\n",
    "    coors_total = coors_total.reshape(-1, ndim) * shape_scale\n",
    "    for i in range(batch_size):\n",
    "        np.random.shuffle(coors_total)\n",
    "        inds_total = coors_total[:num_points[i]]\n",
    "        inds_total = np.pad(inds_total, ((0, 0), (0, 1)),\n",
    "                            mode=\"constant\",\n",
    "                            constant_values=i)\n",
    "        batch_indices.append(inds_total)\n",
    "    if integer:\n",
    "        sparse_data = np.random.randint(data_range[0],\n",
    "                                        data_range[1],\n",
    "                                        size=[num_points.sum(),\n",
    "                                              num_channels]).astype(dtype)\n",
    "    else:\n",
    "        sparse_data = np.random.uniform(data_range[0],\n",
    "                                        data_range[1],\n",
    "                                        size=[num_points.sum(),\n",
    "                                              num_channels]).astype(dtype)\n",
    "\n",
    "    # sparse_data = np.arange(1, num_points.sum() + 1).astype(np.float32).reshape(5, 1)\n",
    "\n",
    "    res = {\n",
    "        \"features\": sparse_data.astype(dtype),\n",
    "    }\n",
    "    if with_dense:\n",
    "        dense_data = np.zeros([batch_size, num_channels, *dense_shape],\n",
    "                              dtype=sparse_data.dtype)\n",
    "        start = 0\n",
    "        for i, inds in enumerate(batch_indices):\n",
    "            for j, ind in enumerate(inds):\n",
    "                dense_slice = (i, slice(None), *ind[:-1])\n",
    "                dense_data[dense_slice] = sparse_data[start + j]\n",
    "            start += len(inds)\n",
    "        res[\"features_dense\"] = dense_data.astype(dtype)\n",
    "    batch_indices = np.concatenate(batch_indices, axis=0)\n",
    "    res[\"indices\"] = batch_indices.astype(np.int32)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dict = generate_sparse_data(shape = [128, 128, 96], num_points = [1077, 987, 1501, 1324], num_channels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.ascontiguousarray(sparse_dict[\"features\"]).astype(\n",
    "    np.float32)\n",
    "indices = np.ascontiguousarray(\n",
    "    sparse_dict[\"indices\"][:, [3, 0, 1, 2]]).astype(np.int32)\n",
    "\n",
    "indices_t = torch.from_numpy(indices).int().cuda()\n",
    "features_t = torch.from_numpy(features).cuda()\n",
    "\n",
    "sparse_tensor = spconv.SparseConvTensor(features = features_t, indices = indices_t, spatial_shape=(128,128,96), batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128, 128, 96])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_tensor.dense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn.cuda()\n",
    "heatmaps, feature_encodings = sdn(sparse_tensor.dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10, 8, 8, 6]), torch.Size([4, 10, 0]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps.shape, feature_encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.0008, device='cuda:0', grad_fn=<StdBackward0>),\n",
       " tensor(0.0645, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(0.0002, device='cuda:0', grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps.mean(), heatmaps.std(), heatmaps.max(), heatmaps.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.1419e-06, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.0276, device='cuda:0', grad_fn=<StdBackward0>),\n",
       " tensor(0.4506, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(-0.4417, device='cuda:0', grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_encodings.mean(), feature_encodings.std(), feature_encodings.max(), feature_encodings.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
