import pytorch_lightning as pl
import torch

import torch.nn as nn

from utils.heatmap_utils import SoftArgmax3D
from models.DenseNet import HeatmapDenseNet
from models.SubmDenseNet import HeatmapSubmDenseNet, SubmDenseNet

from collections.abc import Sequence

from utils.misc import surface_project_coords
from loss.loss_modules import get_loss_fn

    
class SADenseNet(nn.Module):
    """
    Spatial Attention DenseNet:
    With a DenseNet-like architecture, generate a feature map and (low-resolution) heatmap for each landmark.
    Then, use the heatmap to extract a feature vector for each landmark. The soft-argmax of the heatmap defines
    the coarse landmark prediction. The feature vector generated by the heatmap-weighted sum of the feature map 
    provides a feature encoding for each landmark.
    """

    def __init__(self,
        in_channels: int,
        n_landmarks: int,
        loss_fn: str,
        project_gt: bool = False,
        init_features: int = 64,
        feature_l: int = 256,
        growth_rate: int = 32,
        block_config: Sequence[int] = (6, 12, 24, 16),
        bn_size: int = 4,
        dropout_prob: float = 0.0,
        **kwargs):
        super().__init__()

        self.loss_fn = get_loss_fn(loss_fn)

        self.feature_extractor=HeatmapDenseNet(
            spatial_dims = 3,
            in_channels = in_channels,
            n_landmarks = n_landmarks,
            init_features = init_features,
            feature_l = feature_l,                     
            growth_rate = growth_rate,
            block_config = block_config,
            bn_size = bn_size,
            dropout_prob = dropout_prob,
        )

        self.soft_argmax = SoftArgmax3D()

        self.project_gt = project_gt

    def forward(self, batch):
        x = batch['input']
        heatmaps, feature_encodings = self.feature_extractor(x) # (batch_size, n_landmarks, *spatial_shape), (batch_size, n_landmarks, feature_l)
        batch['heatmaps'] = heatmaps # (batch_size, n_landmarks, *spatial_shape), save the heatmaps for visualization
        coarse_preds = self.soft_argmax(heatmaps) # (batch_size, n_landmarks, 3)

        #Scale the coarse predictions to the original shape
        heatmap_shape = heatmaps.shape[2:]
        original_shape = x.shape[2:]
        scale_factor = [original_shape[i] / heatmap_shape[i] for i in range(3)]
        scaled_coarse_preds = coarse_preds * torch.tensor(scale_factor).to(coarse_preds.device)
        
        batch['coarse_preds'] = scaled_coarse_preds # (batch_size, n_landmarks, 3)
        batch['coarse_features'] = feature_encodings # (batch_size, n_landmarks, feature_l)

        return batch
    
    def calculate_loss(self, batch):
        target = batch['target']
        if self.project_gt:
            #Project targets to surface
            surface = batch['surface']
            target, _ = surface_project_coords(target, surface)

        return self.loss_fn(batch['coarse_preds'], target, batch['loss_mask'])
    
    def calculate_metrics(self, batch, mode):
        metrics = {}

        coarse_preds = batch['coarse_preds']            # (batch_size, n_landmarks, 3)
        target = batch['target']                        # (batch_size, n_landmarks, 3)
        target_indices = batch['target_indices']        # (batch_size, n_landmarks)
        loss_mask = batch['loss_mask']                  # (batch_size, n_landmarks)

        if self.project_gt:
            target = batch['target']
            #Project targets to surface
            surface = batch['surface']
            target, projection_dist = surface_project_coords(target, surface)

            metrics[f'coarse_projection_dist_{mode}'] = projection_dist.mean()

        #Calculate the mean Euclidean distance between the predicted and target landmarks
        distances = torch.norm(coarse_preds - target, dim=-1) # (batch_size, n_landmarks)
        distances_mean, distances_std = distances.mean(), distances.std()

        metrics[f'coarse_mean_distance_{mode}'] = distances_mean
        metrics[f'coarse_std_distance_{mode}'] = distances_std

        #Mask the distances with the loss mask
        distances_masked = distances[loss_mask]
        distances_masked_mean, distances_masked_std = distances_masked.mean(), distances_masked.std()

        metrics[f'coarse_mean_distance_masked_{mode}'] = distances_masked_mean  
        metrics[f'coarse_std_distance_masked_{mode}'] = distances_masked_std

        #Calculate mean Euclidian distance grouped by landmark type
        for i, landmark_type in enumerate(target_indices.unique()):
            landmark_mask = target_indices == landmark_type
            landmark_mask = landmark_mask * loss_mask
            distances_landmark = distances[landmark_mask]
            distances_landmark_mean = distances_landmark.mean()
            metrics[f'coarse_mean_distance_{landmark_type.item()}_{mode}'] = distances_landmark_mean

        return metrics
    
class SMDenseNet(nn.Module):
    """
    Submanifold DenseNet:
    With a SubmDenseNet, directly regress landmark coordinate estimates and landmark-wise features for refinement.
    """
    def __init__(self,
        in_channels: int,
        n_landmarks: int,
        loss_fn: str,
        project_gt: bool = False,
        init_features: int = 64,
        feature_l: int = 256,
        growth_rate: int = 32,
        block_config: Sequence[int] = (6, 12, 24, 16),
        bn_size: int = 4,
        dropout_prob: float = 0.0,
        **kwargs):

        super().__init__()

        self.loss_fn = get_loss_fn(loss_fn)

        self.feature_extractor=SubmDenseNet(
            in_channels = in_channels,
            n_landmarks = n_landmarks,
            init_features = init_features,
            feature_l = feature_l,                     
            growth_rate = growth_rate,
            block_config = block_config,
            bn_size = bn_size,
            dropout_prob = dropout_prob,
        )

        self.project_gt = project_gt

    def forward(self, batch):
        x = batch['input']
        coarse_preds, feature_encodings = self.feature_extractor(x)

        batch['coarse_preds'] = coarse_preds
        batch['coarse_features'] = feature_encodings

        return batch
    
    def calculate_loss(self, batch):
        target = batch['target']
        if self.project_gt:
            #Project targets to surface
            surface = batch['surface']
            target, _ = surface_project_coords(target, surface)

        return self.loss_fn(batch['coarse_preds'], target, batch['loss_mask'])
    
    def calculate_metrics(self, batch, mode):
        metrics = {}

        coarse_preds = batch['coarse_preds']            # (batch_size, n_landmarks, 3)
        target = batch['target']                        # (batch_size, n_landmarks, 3)
        target_indices = batch['target_indices']        # (batch_size, n_landmarks)
        loss_mask = batch['loss_mask']                  # (batch_size, n_landmarks)

        if self.project_gt:
            target = batch['target']
            #Project targets to surface
            surface = batch['surface']
            target, projection_dist = surface_project_coords(target, surface)

            metrics[f'coarse_projection_dist_{mode}'] = projection_dist.mean()

        #Calculate the mean Euclidean distance between the predicted and target landmarks
        distances = torch.norm(coarse_preds - target, dim=-1)

        distances_mean, distances_std = distances.mean(), distances.std()

        metrics[f'coarse_mean_distance_{mode}'] = distances_mean
        metrics[f'coarse_std_distance_{mode}'] = distances_std

        #Mask the distances with the loss mask
        distances_masked = distances[loss_mask]
        distances_masked_mean, distances_masked_std = distances_masked.mean(), distances_masked.std()

        metrics[f'coarse_mean_distance_masked_{mode}'] = distances_masked_mean
        metrics[f'coarse_std_distance_masked_{mode}'] = distances_masked_std

        #Calculate mean Euclidian distance grouped by landmark type
        for i, landmark_type in enumerate(target_indices.unique()):
            landmark_mask = target_indices == landmark_type
            landmark_mask = landmark_mask * loss_mask
            distances_landmark = distances[landmark_mask]
            distances_landmark_mean = distances_landmark.mean()
            metrics[f'coarse_mean_distance_{landmark_type.item()}_{mode}'] = distances_landmark_mean

        return metrics

     
class SMSADenseNet(nn.Module):
    """
    Submanifold Spatial Attention DenseNet:
    With a SubmDenseNet, generate a feature map and (low-resolution) heatmap for each landmark.
    Then, use the heatmap to extract a feature vector for each landmark. The soft-argmax of the heatmap defines
    the coarse landmark prediction. The feature vector generated by the heatmap-weighted sum of the feature map 
    provides a feature encoding for each landmark.
    """
    def __init__(self,
        in_channels: int,
        n_landmarks: int,
        loss_fn: str,
        project_gt: bool = False,
        init_features: int = 64,
        feature_l: int = 256,
        growth_rate: int = 32,
        block_config: Sequence[int] = (6, 12, 24, 16),
        bn_size: int = 4,
        dropout_prob: float = 0.0,
        **kwargs):
            super().__init__()

            self.loss_fn = get_loss_fn(loss_fn)

            self.project_gt = project_gt

            self.feature_extractor=HeatmapSubmDenseNet(
                in_channels = in_channels,
                n_landmarks = n_landmarks,
                init_features = init_features,
                feature_l = feature_l,                     
                growth_rate = growth_rate,
                block_config = block_config,
                bn_size = bn_size,
                dropout_prob = dropout_prob,
            )

            self.soft_argmax = SoftArgmax3D()

    def forward(self, batch):
        #Only keep input that lies on the surface
        x = batch['input'] * batch['surface']
        heatmaps, feature_encodings = self.feature_extractor(x) # (batch_size, n_landmarks, *spatial_shape), (batch_size, n_landmarks, feature_l)
        batch['heatmaps'] = heatmaps # (batch_size, n_landmarks, *spatial_shape), save the heatmaps for visualization
        coarse_preds = self.soft_argmax(heatmaps) # (batch_size, n_landmarks, 3)
        
        #Scale the coarse predictions to the original shape
        heatmap_shape = heatmaps.shape[2:]
        original_shape = x.shape[2:]
        scale_factor = [original_shape[i] / heatmap_shape[i] for i in range(3)]
        scaled_coarse_preds = coarse_preds * torch.tensor(scale_factor).to(coarse_preds.device)
        
        batch['coarse_preds'] = scaled_coarse_preds # (batch_size, n_landmarks, 3)
        batch['coarse_features'] = feature_encodings # (batch_size, n_landmarks, feature_l)

        return batch
    
    def calculate_loss(self, batch):
        target = batch['target']
        if self.project_gt:
            #Project targets to surface
            surface = batch['surface']
            target, _ = surface_project_coords(target, surface)

        return self.loss_fn(batch['coarse_preds'], target, batch['loss_mask'])
    
    def calculate_metrics(self, batch, mode):
        metrics = {}

        coarse_preds = batch['coarse_preds']            # (batch_size, n_landmarks, 3)
        target = batch['target']                        # (batch_size, n_landmarks, 3)
        target_indices = batch['target_indices']        # (batch_size, n_landmarks)
        loss_mask = batch['loss_mask']                  # (batch_size, n_landmarks)

        if self.project_gt:
            target = batch['target']
            #Project targets to surface
            surface = batch['surface']
            target, projection_dist = surface_project_coords(target, surface)

            metrics[f'coarse_projection_dist_{mode}'] = projection_dist.mean()

        #Calculate the mean Euclidean distance between the predicted and target landmarks
        distances = torch.norm(coarse_preds - target, dim=-1) # (batch_size, n_landmarks)
        distances_mean, distances_std = distances.mean(), distances.std()

        metrics[f'coarse_mean_distance_{mode}'] = distances_mean
        metrics[f'coarse_std_distance_{mode}'] = distances_std

        #Mask the distances with the loss mask
        distances_masked = distances[loss_mask]
        distances_masked_mean, distances_masked_std = distances_masked.mean(), distances_masked.std()

        metrics[f'coarse_mean_distance_masked_{mode}'] = distances_masked_mean  
        metrics[f'coarse_std_distance_masked_{mode}'] = distances_masked_std

        #Calculate mean Euclidian distance grouped by landmark type
        for i, landmark_type in enumerate(target_indices.unique()):
            landmark_mask = target_indices == landmark_type
            landmark_mask = landmark_mask * loss_mask
            distances_landmark = distances[landmark_mask]
            distances_landmark_mean = distances_landmark.mean()
            metrics[f'coarse_mean_distance_{landmark_type.item()}_{mode}'] = distances_landmark_mean

        return metrics