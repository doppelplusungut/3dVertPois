from collections.abc import Sequence

import torch
import torch.nn as nn

from loss.loss_modules import get_loss_fn
from models.DenseNet import HeatmapDenseNet
from models.SubmDenseNet import HeatmapSubmDenseNet, SubmDenseNet
from utils.heatmap_utils import SoftArgmax3D
from utils.misc import surface_project_coords


class SADenseNet(nn.Module):
    """
    Spatial Attention DenseNet:
    With a DenseNet-like architecture, generate a feature map and (low-resolution) heatmap for each landmark.
    Then, use the heatmap to extract a feature vector for each landmark. The soft-argmax of the heatmap defines
    the coarse landmark prediction. The feature vector generated by the heatmap-weighted sum of the feature map
    provides a feature encoding for each landmark.
    """

    def __init__(
        self,
        in_channels: int,
        n_landmarks: int,
        loss_fn: str,
        project_gt: bool = False,
        init_features: int = 64,
        feature_l: int = 256,
        growth_rate: int = 32,
        block_config: Sequence[int] = (6, 12, 24, 16),
        bn_size: int = 4,
        dropout_prob: float = 0.0,
        **kwargs,
    ):
        super().__init__()

        self.loss_fn = get_loss_fn(loss_fn)

        self.feature_extractor = HeatmapDenseNet(
            spatial_dims=3,
            in_channels=in_channels,
            n_landmarks=n_landmarks,
            init_features=init_features,
            feature_l=feature_l,
            growth_rate=growth_rate,
            block_config=block_config,
            bn_size=bn_size,
            dropout_prob=dropout_prob,
        )

        self.soft_argmax = SoftArgmax3D()

        self.project_gt = project_gt

    def forward(self, batch):
        x = batch["input"]
        heatmaps, feature_encodings = self.feature_extractor(
            x
        )  # (batch_size, n_landmarks, *spatial_shape), (batch_size, n_landmarks, feature_l)
        batch["heatmaps"] = (
            heatmaps  # (batch_size, n_landmarks, *spatial_shape), save the heatmaps for visualization
        )
        coarse_preds = self.soft_argmax(heatmaps)  # (batch_size, n_landmarks, 3)

        # Scale the coarse predictions to the original shape
        heatmap_shape = heatmaps.shape[2:]
        original_shape = x.shape[2:]
        scale_factor = [original_shape[i] / heatmap_shape[i] for i in range(3)]
        scaled_coarse_preds = coarse_preds * torch.tensor(scale_factor).to(
            coarse_preds.device
        )

        batch["coarse_preds"] = scaled_coarse_preds  # (batch_size, n_landmarks, 3)
        batch["coarse_features"] = (
            feature_encodings  # (batch_size, n_landmarks, feature_l)
        )

        return batch

    def calculate_loss(self, batch):
        target = batch["target"]
        if self.project_gt:
            # Project targets to surface
            surface = batch["surface"]
            target, _ = surface_project_coords(target, surface)

        return self.loss_fn(batch["coarse_preds"], target, batch["loss_mask"])

    def calculate_metrics(self, batch, mode):
        metrics = {}

        coarse_preds = batch["coarse_preds"]  # (batch_size, n_landmarks, 3)
        target = batch["target"]  # (batch_size, n_landmarks, 3)
        target_indices = batch["target_indices"]  # (batch_size, n_landmarks)
        loss_mask = batch["loss_mask"]  # (batch_size, n_landmarks)

        if self.project_gt:
            target = batch["target"]
            # Project targets to surface
            surface = batch["surface"]
            target, projection_dist = surface_project_coords(target, surface)

            metrics[f"coarse_projection_dist_{mode}"] = projection_dist.mean()

        # Calculate the mean Euclidean distance between the predicted and target landmarks
        distances = torch.norm(
            coarse_preds - target, dim=-1
        )  # (batch_size, n_landmarks)
        distances_mean, distances_std = distances.mean(), distances.std()

        metrics[f"coarse_mean_distance_{mode}"] = distances_mean
        metrics[f"coarse_std_distance_{mode}"] = distances_std

        # Mask the distances with the loss mask
        distances_masked = distances[loss_mask]
        distances_masked_mean, distances_masked_std = (
            distances_masked.mean(),
            distances_masked.std(),
        )

        metrics[f"coarse_mean_distance_masked_{mode}"] = distances_masked_mean
        metrics[f"coarse_std_distance_masked_{mode}"] = distances_masked_std

        # Calculate mean Euclidian distance grouped by landmark type
        for i, landmark_type in enumerate(target_indices.unique()):
            landmark_mask = target_indices == landmark_type
            landmark_mask = landmark_mask * loss_mask
            distances_landmark = distances[landmark_mask]
            distances_landmark_mean = distances_landmark.mean()
            metrics[f"coarse_mean_distance_{landmark_type.item()}_{mode}"] = (
                distances_landmark_mean
            )

        return metrics


class SMDenseNet(nn.Module):
    """
    Submanifold DenseNet:
    With a SubmDenseNet, directly regress landmark coordinate estimates and landmark-wise features for refinement.
    """

    def __init__(
        self,
        in_channels: int,
        n_landmarks: int,
        loss_fn: str,
        project_gt: bool = False,
        init_features: int = 64,
        feature_l: int = 256,
        growth_rate: int = 32,
        block_config: Sequence[int] = (6, 12, 24, 16),
        bn_size: int = 4,
        dropout_prob: float = 0.0,
        **kwargs,
    ):

        super().__init__()

        self.loss_fn = get_loss_fn(loss_fn)

        self.feature_extractor = SubmDenseNet(
            in_channels=in_channels,
            n_landmarks=n_landmarks,
            init_features=init_features,
            feature_l=feature_l,
            growth_rate=growth_rate,
            block_config=block_config,
            bn_size=bn_size,
            dropout_prob=dropout_prob,
        )

        self.project_gt = project_gt

    def forward(self, batch):
        x = batch["input"]
        coarse_preds, feature_encodings = self.feature_extractor(x)

        batch["coarse_preds"] = coarse_preds
        batch["coarse_features"] = feature_encodings

        return batch

    def calculate_loss(self, batch):
        target = batch["target"]
        if self.project_gt:
            # Project targets to surface
            surface = batch["surface"]
            target, _ = surface_project_coords(target, surface)

        return self.loss_fn(batch["coarse_preds"], target, batch["loss_mask"])

    def calculate_metrics(self, batch, mode):
        metrics = {}

        coarse_preds = batch["coarse_preds"]  # (batch_size, n_landmarks, 3)
        target = batch["target"]  # (batch_size, n_landmarks, 3)
        target_indices = batch["target_indices"]  # (batch_size, n_landmarks)
        loss_mask = batch["loss_mask"]  # (batch_size, n_landmarks)

        if self.project_gt:
            target = batch["target"]
            # Project targets to surface
            surface = batch["surface"]
            target, projection_dist = surface_project_coords(target, surface)

            metrics[f"coarse_projection_dist_{mode}"] = projection_dist.mean()

        # Calculate the mean Euclidean distance between the predicted and target landmarks
        distances = torch.norm(coarse_preds - target, dim=-1)

        distances_mean, distances_std = distances.mean(), distances.std()

        metrics[f"coarse_mean_distance_{mode}"] = distances_mean
        metrics[f"coarse_std_distance_{mode}"] = distances_std

        # Mask the distances with the loss mask
        distances_masked = distances[loss_mask]
        distances_masked_mean, distances_masked_std = (
            distances_masked.mean(),
            distances_masked.std(),
        )

        metrics[f"coarse_mean_distance_masked_{mode}"] = distances_masked_mean
        metrics[f"coarse_std_distance_masked_{mode}"] = distances_masked_std

        # Calculate mean Euclidian distance grouped by landmark type
        for i, landmark_type in enumerate(target_indices.unique()):
            landmark_mask = target_indices == landmark_type
            landmark_mask = landmark_mask * loss_mask
            distances_landmark = distances[landmark_mask]
            distances_landmark_mean = distances_landmark.mean()
            metrics[f"coarse_mean_distance_{landmark_type.item()}_{mode}"] = (
                distances_landmark_mean
            )

        return metrics


class SMSADenseNet(nn.Module):
    """
    Submanifold Spatial Attention DenseNet:
    With a SubmDenseNet, generate a feature map and (low-resolution) heatmap for each landmark.
    Then, use the heatmap to extract a feature vector for each landmark. The soft-argmax of the heatmap defines
    the coarse landmark prediction. The feature vector generated by the heatmap-weighted sum of the feature map
    provides a feature encoding for each landmark.
    """

    def __init__(
        self,
        in_channels: int,
        n_landmarks: int,
        loss_fn: str,
        project_gt: bool = False,
        init_features: int = 64,
        feature_l: int = 256,
        growth_rate: int = 32,
        block_config: Sequence[int] = (6, 12, 24, 16),
        bn_size: int = 4,
        dropout_prob: float = 0.0,
        **kwargs,
    ):
        super().__init__()

        self.loss_fn = get_loss_fn(loss_fn)

        self.project_gt = project_gt

        self.feature_extractor = HeatmapSubmDenseNet(
            in_channels=in_channels,
            n_landmarks=n_landmarks,
            init_features=init_features,
            feature_l=feature_l,
            growth_rate=growth_rate,
            block_config=block_config,
            bn_size=bn_size,
            dropout_prob=dropout_prob,
        )

        self.soft_argmax = SoftArgmax3D()

    def forward(self, batch):
        # Only keep input that lies on the surface
        x = batch["input"] * batch["surface"]
        heatmaps, feature_encodings = self.feature_extractor(
            x
        )  # (batch_size, n_landmarks, *spatial_shape), (batch_size, n_landmarks, feature_l)
        batch["heatmaps"] = (
            heatmaps  # (batch_size, n_landmarks, *spatial_shape), save the heatmaps for visualization
        )
        coarse_preds = self.soft_argmax(heatmaps)  # (batch_size, n_landmarks, 3)

        # Scale the coarse predictions to the original shape
        heatmap_shape = heatmaps.shape[2:]
        original_shape = x.shape[2:]
        scale_factor = [original_shape[i] / heatmap_shape[i] for i in range(3)]
        scaled_coarse_preds = coarse_preds * torch.tensor(scale_factor).to(
            coarse_preds.device
        )

        batch["coarse_preds"] = scaled_coarse_preds  # (batch_size, n_landmarks, 3)
        batch["coarse_features"] = (
            feature_encodings  # (batch_size, n_landmarks, feature_l)
        )

        return batch

    def calculate_loss(self, batch):
        target = batch["target"]
        if self.project_gt:
            # Project targets to surface
            surface = batch["surface"]
            target, _ = surface_project_coords(target, surface)

        return self.loss_fn(batch["coarse_preds"], target, batch["loss_mask"])

    def calculate_metrics(self, batch, mode):
        metrics = {}

        coarse_preds = batch["coarse_preds"]  # (batch_size, n_landmarks, 3)
        target = batch["target"]  # (batch_size, n_landmarks, 3)
        target_indices = batch["target_indices"]  # (batch_size, n_landmarks)
        loss_mask = batch["loss_mask"]  # (batch_size, n_landmarks)

        if self.project_gt:
            target = batch["target"]
            # Project targets to surface
            surface = batch["surface"]
            target, projection_dist = surface_project_coords(target, surface)

            metrics[f"coarse_projection_dist_{mode}"] = projection_dist.mean()

        # Calculate the mean Euclidean distance between the predicted and target landmarks
        distances = torch.norm(
            coarse_preds - target, dim=-1
        )  # (batch_size, n_landmarks)
        distances_mean, distances_std = distances.mean(), distances.std()

        metrics[f"coarse_mean_distance_{mode}"] = distances_mean
        metrics[f"coarse_std_distance_{mode}"] = distances_std

        # Mask the distances with the loss mask
        distances_masked = distances[loss_mask]
        distances_masked_mean, distances_masked_std = (
            distances_masked.mean(),
            distances_masked.std(),
        )

        metrics[f"coarse_mean_distance_masked_{mode}"] = distances_masked_mean
        metrics[f"coarse_std_distance_masked_{mode}"] = distances_masked_std

        # Calculate mean Euclidian distance grouped by landmark type
        for i, landmark_type in enumerate(target_indices.unique()):
            landmark_mask = target_indices == landmark_type
            landmark_mask = landmark_mask * loss_mask
            distances_landmark = distances[landmark_mask]
            distances_landmark_mean = distances_landmark.mean()
            metrics[f"coarse_mean_distance_{landmark_type.item()}_{mode}"] = (
                distances_landmark_mean
            )

        return metrics
